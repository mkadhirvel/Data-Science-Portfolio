{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2289661",
   "metadata": {},
   "source": [
    "# DSC 540\n",
    "# Week 7&8\n",
    "# Author: Muthukumar Kadhirvel\n",
    "# 5/3/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a9bbb",
   "metadata": {},
   "source": [
    "# Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3c855",
   "metadata": {},
   "source": [
    "Create a pandas dataframe of the 50 highest grossing films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d2e015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rank Peak                         Title Worldwide gross  Year Reference(s)\n",
      "0    1    1                        Avatar  $2,847,246,203  2009   [# 1][# 2]\n",
      "1    2    1             Avengers: Endgame  $2,797,501,328  2019   [# 3][# 4]\n",
      "2    3    1                       Titanic  $2,187,425,379  1997   [# 5][# 6]\n",
      "3    4    3  Star Wars: The Force Awakens  $2,068,223,624  2015   [# 7][# 8]\n",
      "4    5    4        Avengers: Infinity War  $2,048,359,754  2018  [# 9][# 10]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_highest-grossing_films'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'lxml')\n",
    "table_data = soup.find(\"table\", {\"class\":'wikitable sortable plainrowheaders'})\n",
    "headers = []\n",
    "for i in table_data.find(\"tbody\").find(\"tr\").findAll(\"th\"):\n",
    "    headers.append(i.getText().strip())\n",
    "rows = []\n",
    "# The third column is a header field and so we need to take the first 2 \"tr\" records and then the \"th\" record and then the\n",
    "# last 3 \"tr\" records.\n",
    "for i in table_data.findAll(\"tr\")[1:]:\n",
    "    sub_rows = []\n",
    "    for x in i.findAll(\"td\", limit=2):\n",
    "        sub_rows.append(x.getText().strip())\n",
    "    for x in i.findAll(\"th\"):\n",
    "        sub_rows.append(x.getText().strip())\n",
    "    for x in i.findAll(\"td\")[2:]:\n",
    "        sub_rows.append(x.getText().strip())\n",
    "    rows.append(sub_rows)\n",
    "eng_df = pd.DataFrame(rows,columns=headers)\n",
    "print(eng_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f7252",
   "metadata": {},
   "source": [
    "Create a pandas dataframe of the 50 highest grossing Non English films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24ed4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rank             English title[b] Original title Primarylanguage(s)[c]  \\\n",
      "0    1  The Battle at Lake Changjin            长津湖              Mandarin   \n",
      "1    2               Wolf Warrior 2            战狼2  Mandarin[19][20][21]   \n",
      "2    3                      Hi, Mom         你好，李焕英              Mandarin   \n",
      "3    4                       Ne Zha        哪吒之魔童降世              Mandarin   \n",
      "4    5          The Wandering Earth           流浪地球              Mandarin   \n",
      "\n",
      "  Countryof origin Worldwidegross (in US$)  Year       Ref  \n",
      "0            China            $913 million  2021  [17][18]  \n",
      "1            China            $874 million  2017      [22]  \n",
      "2            China            $848 million  2021      [23]  \n",
      "3            China            $743 million  2019      [24]  \n",
      "4            China            $699 million  2019      [25]  \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_highest-grossing_non-English_films'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'lxml')\n",
    "table_data = soup.find(\"table\", {\"class\":'wikitable sortable'})\n",
    "headers = []\n",
    "for i in table_data.find(\"tbody\").find(\"tr\").findAll(\"th\"):\n",
    "    headers.append(i.getText().strip())\n",
    "rows = []\n",
    "for i in table_data.findAll(\"tr\")[1:]:\n",
    "    sub_rows = []\n",
    "    for x in i.findAll(\"td\"):\n",
    "        sub_rows.append(x.getText().strip())\n",
    "    rows.append(sub_rows)\n",
    "non_eng_df = pd.DataFrame(rows,columns=headers)\n",
    "print(non_eng_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf7ec2",
   "metadata": {},
   "source": [
    "Step 1 - Drop Unnecessary columns                                                                                               \n",
    "We are dropping the following columns as they have data that is irrelevant to the problem we are trying to solve.\n",
    "Rank/Peak/References/Original title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc248bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Title Worldwide gross  Year\n",
      "0                        Avatar  $2,847,246,203  2009\n",
      "1             Avengers: Endgame  $2,797,501,328  2019\n",
      "2                       Titanic  $2,187,425,379  1997\n",
      "3  Star Wars: The Force Awakens  $2,068,223,624  2015\n",
      "4        Avengers: Infinity War  $2,048,359,754  2018\n",
      "              English title[b] Primarylanguage(s)[c] Countryof origin  \\\n",
      "0  The Battle at Lake Changjin              Mandarin            China   \n",
      "1               Wolf Warrior 2  Mandarin[19][20][21]            China   \n",
      "2                      Hi, Mom              Mandarin            China   \n",
      "3                       Ne Zha              Mandarin            China   \n",
      "4          The Wandering Earth              Mandarin            China   \n",
      "\n",
      "  Worldwidegross (in US$)  Year  \n",
      "0            $913 million  2021  \n",
      "1            $874 million  2017  \n",
      "2            $848 million  2021  \n",
      "3            $743 million  2019  \n",
      "4            $699 million  2019  \n"
     ]
    }
   ],
   "source": [
    "eng_df = eng_df.drop(['Rank','Peak','Reference(s)'], axis=1)\n",
    "non_eng_df = non_eng_df.drop(['Rank','Original title','Ref'], axis=1)\n",
    "print(eng_df.head())\n",
    "print(non_eng_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9108f",
   "metadata": {},
   "source": [
    "Step 2 - Rearrange & Replace Headers                                                                                           We will rename and rearrange the columns to make more sense in the order of impactful columns.                                 \n",
    "We will add new Language and Country columns to the eng_df to make it standard alongside non_eng_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9294b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Title Country Language  Year  \\\n",
      "0                        Avatar     USA  English  2009   \n",
      "1             Avengers: Endgame     USA  English  2019   \n",
      "2                       Titanic     USA  English  1997   \n",
      "3  Star Wars: The Force Awakens     USA  English  2015   \n",
      "4        Avengers: Infinity War     USA  English  2018   \n",
      "\n",
      "  Worldwide_Gross(Million$)  \n",
      "0            $2,847,246,203  \n",
      "1            $2,797,501,328  \n",
      "2            $2,187,425,379  \n",
      "3            $2,068,223,624  \n",
      "4            $2,048,359,754  \n",
      "                         Title Country              Language  Year  \\\n",
      "0  The Battle at Lake Changjin   China              Mandarin  2021   \n",
      "1               Wolf Warrior 2   China  Mandarin[19][20][21]  2017   \n",
      "2                      Hi, Mom   China              Mandarin  2021   \n",
      "3                       Ne Zha   China              Mandarin  2019   \n",
      "4          The Wandering Earth   China              Mandarin  2019   \n",
      "\n",
      "  Worldwide_Gross(Million$)  \n",
      "0              $913 million  \n",
      "1              $874 million  \n",
      "2              $848 million  \n",
      "3              $743 million  \n",
      "4              $699 million  \n"
     ]
    }
   ],
   "source": [
    "eng_df.rename(columns = {'Worldwide gross':'Worldwide_Gross(Million$)'}, inplace = True)\n",
    "non_eng_df.rename(columns = {'English title[b]':'Title', 'Primarylanguage(s)[c]':'Language'}, inplace = True)\n",
    "non_eng_df.rename(columns = {'Countryof origin':'Country', 'Worldwidegross (in US$)':'Worldwide_Gross(Million$)'}, inplace = True)\n",
    "eng_df['Language'] = 'English'\n",
    "eng_df['Country'] = 'USA'\n",
    "eng_df = eng_df[['Title','Country','Language','Year','Worldwide_Gross(Million$)']]\n",
    "non_eng_df = non_eng_df[['Title','Country','Language','Year','Worldwide_Gross(Million$)']]\n",
    "print(eng_df.head())\n",
    "print(non_eng_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a47ae",
   "metadata": {},
   "source": [
    "Step 3 - Format data into a more readable format                                                                               \n",
    "Convert Gross to a standard format across both the dataframes                                                                   \n",
    "Country and Language has multiple values and so keep only the first value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfee3b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Title Country Language  Year  \\\n",
      "0                        Avatar     USA  English  2009   \n",
      "1             Avengers: Endgame     USA  English  2019   \n",
      "2                       Titanic     USA  English  1997   \n",
      "3  Star Wars: The Force Awakens     USA  English  2015   \n",
      "4        Avengers: Infinity War     USA  English  2018   \n",
      "\n",
      "  Worldwide_Gross(Million$)  \n",
      "0                   2847.25  \n",
      "1                    2797.5  \n",
      "2                   2187.43  \n",
      "3                   2068.22  \n",
      "4                   2048.36  \n",
      "                         Title Country  Language  Year  \\\n",
      "0  The Battle at Lake Changjin   China  Mandarin  2021   \n",
      "1               Wolf Warrior 2   China  Mandarin  2017   \n",
      "2                      Hi, Mom   China  Mandarin  2021   \n",
      "3                       Ne Zha   China  Mandarin  2019   \n",
      "4          The Wandering Earth   China  Mandarin  2019   \n",
      "\n",
      "  Worldwide_Gross(Million$)  \n",
      "0                     913.0  \n",
      "1                     874.0  \n",
      "2                     848.0  \n",
      "3                     743.0  \n",
      "4                     699.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muthu\\AppData\\Local\\Temp/ipykernel_10888/3307390705.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  temp = temp.astype(str).str.replace('[$,]', '')\n",
      "C:\\Users\\Muthu\\AppData\\Local\\Temp/ipykernel_10888/3307390705.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  temp = temp.astype(str).str.replace('$', '')\n"
     ]
    }
   ],
   "source": [
    "# Remove invalid characters and '$' and ',' from the Gross so it can be converted to numerics and then to millions\n",
    "temp = eng_df['Worldwide_Gross(Million$)'].astype(str).str.lstrip(\"F8\")\n",
    "temp = temp.astype(str).str.replace('[$,]', '')\n",
    "millions = pd.to_numeric(temp, errors='coerce')/1e6\n",
    "eng_df['Worldwide_Gross(Million$)'] = millions.round(2).astype(str)\n",
    "# Remove million and '$' from the Gross \n",
    "temp = non_eng_df['Worldwide_Gross(Million$)'].astype(str).str.replace('million', '')\n",
    "temp = temp.astype(str).str.replace('$', '')\n",
    "millions = pd.to_numeric(temp, errors='coerce')\n",
    "non_eng_df['Worldwide_Gross(Million$)'] = millions.round(2).astype(str)\n",
    "# Keep only the first value \n",
    "non_eng_df['Country'] = [x.split('\\n')[0] for x in non_eng_df['Country']]\n",
    "non_eng_df['Language'] = [x.split('\\n')[0] for x in non_eng_df['Language']]\n",
    "non_eng_df['Language'] = [x.split('[')[0] for x in non_eng_df['Language']]\n",
    "print(eng_df.head())\n",
    "print(non_eng_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9138d5e2",
   "metadata": {},
   "source": [
    "Step 4 - Combine datasets                                                                                                       \n",
    "Combine both the datasets into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f02c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Title    Country   Language  Year  \\\n",
      "0                           Avatar        USA    English  2009   \n",
      "1                Avengers: Endgame        USA    English  2019   \n",
      "2                          Titanic        USA    English  1997   \n",
      "3     Star Wars: The Force Awakens        USA    English  2015   \n",
      "4           Avengers: Infinity War        USA    English  2018   \n",
      "..                             ...        ...        ...   ...   \n",
      "95                     Better Days      China   Mandarin  2019   \n",
      "96                     Raging Fire  Hong Kong  Cantonese  2021   \n",
      "97          My Country, My Parents      China   Mandarin  2021   \n",
      "98             A Little Red Flower      China   Mandarin  2020   \n",
      "99  Crouching Tiger, Hidden Dragon      China   Mandarin  2000   \n",
      "\n",
      "   Worldwide_Gross(Million$)  \n",
      "0                    2847.25  \n",
      "1                     2797.5  \n",
      "2                    2187.43  \n",
      "3                    2068.22  \n",
      "4                    2048.36  \n",
      "..                       ...  \n",
      "95                     226.0  \n",
      "96                     225.0  \n",
      "97                     221.0  \n",
      "98                     216.0  \n",
      "99                     214.0  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.concat([eng_df,non_eng_df],ignore_index=True)\n",
    "print(movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991348d",
   "metadata": {},
   "source": [
    "Step 5 - Add new column                                                                                                          Add a new Rank column that orders it based on Worldwide Gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e635d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                           Title    Country   Language  Year  \\\n",
      "0      1                          Avatar        USA    English  2009   \n",
      "1      2               Avengers: Endgame        USA    English  2019   \n",
      "2      3                         Titanic        USA    English  1997   \n",
      "3      4    Star Wars: The Force Awakens        USA    English  2015   \n",
      "4      5          Avengers: Infinity War        USA    English  2018   \n",
      "..   ...                             ...        ...        ...   ...   \n",
      "95    96                     Better Days      China   Mandarin  2019   \n",
      "96    97                     Raging Fire  Hong Kong  Cantonese  2021   \n",
      "97    98          My Country, My Parents      China   Mandarin  2021   \n",
      "98    99             A Little Red Flower      China   Mandarin  2020   \n",
      "99   100  Crouching Tiger, Hidden Dragon      China   Mandarin  2000   \n",
      "\n",
      "    Worldwide_Gross(Million$)  \n",
      "0                     2847.25  \n",
      "1                     2797.50  \n",
      "2                     2187.43  \n",
      "3                     2068.22  \n",
      "4                     2048.36  \n",
      "..                        ...  \n",
      "95                     226.00  \n",
      "96                     225.00  \n",
      "97                     221.00  \n",
      "98                     216.00  \n",
      "99                     214.00  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "movies_df['Worldwide_Gross(Million$)'] = movies_df['Worldwide_Gross(Million$)'].astype(float)\n",
    "movies_df = movies_df.sort_values(by=['Worldwide_Gross(Million$)'],ignore_index=True,ascending=False)\n",
    "movies_df.insert(0, 'Rank', range(1, 1 + len(movies_df)))\n",
    "print(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad1390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
